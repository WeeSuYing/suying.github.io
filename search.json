[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Portfolio",
    "section": "",
    "text": "Welcome to Su Ying’s projects.\nClick on the Customer Churn Project to look through my school projects at SMU."
  },
  {
    "objectID": "docs/customer_churn_github.html",
    "href": "docs/customer_churn_github.html",
    "title": "Customer Churn Project",
    "section": "",
    "text": "For this project, our group worked on a customer churn dataset. This dataset is centred around a telecommunications company, where it provides information on how customers are utilising the services and also indicates whether a customer has churned.\nThis project aims to propose a model to predict potential customer churners. To do so, spark will be leveraged to push computations and techniques such as exploratory data analysis and modelling will be employed."
  },
  {
    "objectID": "docs/customer_churn_github.html#customer-churn-logistic-modelling",
    "href": "docs/customer_churn_github.html#customer-churn-logistic-modelling",
    "title": "Customer Churn Project",
    "section": "",
    "text": "For this project, our group worked on a customer churn dataset. This dataset is centred around a telecommunications company, where it provides information on how customers are utilising the services and also indicates whether a customer has churned.\nThis project aims to propose a model to predict potential customer churners. To do so, spark will be leveraged to push computations and techniques such as exploratory data analysis and modelling will be employed."
  },
  {
    "objectID": "docs/customer_churn_github.html#exploratory-data-analysis-eda",
    "href": "docs/customer_churn_github.html#exploratory-data-analysis-eda",
    "title": "Customer Churn Project",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\nTo better understand our data set, we conducted EDA to examine the distribution of independent variables and their relationships with the dependent variable. To enhance the clarity in our visualizations, we labelled Churn (1 and 0) as “Churn” and “Non-Churn” respectively. The figures accompanying our analysis can be found in the Appendix.\n\nEDA Visualisations\n\nDistribution of Churn customers\n\nWe observe a relatively equal distribution of churn and non-churn customers, with 280,492 and 224,714 instances, respectively. This balanced class distribution ensures that the dataset will not introduce bias in model prediction and prevent the model from favouring the majority class.\n\n\nDistribution of Age between Churn customers\n\nWe can observe that among churn customers, age is uniformly distributed across the 20 to 60 years old range. In contrast, non-churn customers tend to be concentrated between 30 and 50 years old, with a notable decrease in the proportion of aged 50 to 60 years old. Since there is a notable difference in the distribution, Age is possibly a significant variable.\n\n\nDistribution of Gender between Churn customers\n\nWe notice that among churn customers, the number of males and females is quite similar. In contrast, among non-churn customers, there is a considerably higher count of males compared to females. Disparity in distribution suggests that Gender might be significant.\n\n\nDistribution of Tenure between Churn customers\n\nThe distribution of tenure does not show a notable disparity between churn and non-churn customers. There are minor variations, with non-churn customers showing slightly higher and lower proportions in the 10 and 20 months range respectively. This suggests that Tenure might be insignificant.\n\n\nDistribution of Usage Frequency between Churn customers\n\nThere is a small difference in the distribution of usage frequency within the 0-10 days range, with a slightly higher proportion of churn customers compared to non-churn customers. As such, Usage Frequency might be insignificant.\n\n\nDistribution of Support Calls between Churn customers\n\nThe majority of non-churn customers make fewer than 4 support calls. As a result, for support call counts less than 4, there are more non-churn customers than churn customers, while the opposite is observed for support call counts between 4 and 10. Notable difference in distribution suggests that Support Calls are significant.\n\n\nDistribution of Payment Delay between Churn customers\n\nWe observe that non-churn customers are concentrated in less than 20 days. However, among churn customers, the distribution is more even, with a slightly higher proportion having payment delays exceeding 20 days. Disparity in distribution seems to suggest that Payment Delay is significant.\n\n\nDistribution of Subscription Type between Churn customers\n\nWe do not observe any distinction in the subscription preferences among churn and non-churn customers respectively. Therefore, Subscription Type might be insignificant.\n\n\nDistribution of Contract Length between Churn customers\n\nWe noticed that non-churn customers tend to avoid signing up for monthly contracts. Whereas, for churn customers, there is a relatively even distribution. Huge difference in distribution suggests that Contact Length might be significant.\n\n\nDistribution of Spending Amount between Churn customers\n\nWe can observe that churn customers exhibit a relatively even distribution in terms of total amount spent, whereas non-churn customers tend to concentrate on total amount spent exceeding $500 range. Disparity in distribution seems to suggest that Total Spend might be significant.\n\n\nDistribution of Last Interaction between Churn customers\n\nWe observe that churn customers show a relatively even distribution in terms of the number of days since their last interaction with the company. In contrast, a significant proportion of non-churn customers are concentrated around less than 15 days since their last interaction. Notable difference in distribution suggests that Last Interaction is significant.\n\n\nCorrelation Matrix\n\n\n\n\nEDA Code\n# Churn vs Non-Churn\nsql &lt;- \"SELECT IF(Churn = 1.0, 'Churn', 'Non-Churn') AS `Customer Type`,\n        COUNT(Churn) AS `Number of Customers`,\n        COUNT(Churn) / SUM(COUNT(Churn)) OVER () AS Proportion\n        FROM Customer\n        GROUP BY Churn\"\n\nchurn &lt;- DBI::dbGetQuery(sc, sql)\n\nchurn &lt;- customer |&gt;\n  mutate(`Customer Type` = ifelse(Churn == 1.0, 'Churn', 'Non-Churn')) |&gt;\n  group_by(`Customer Type`) |&gt;\n  summarize(`Number of Customers` = n()) |&gt;\n  mutate(Proportion = `Number of Customers` / sum(`Number of Customers`)) |&gt;\n  collect()\n\nchurn |&gt;\n  ggplot(aes(x= `Customer Type`, y = `Number of Customers`, fill = `Customer Type`)) +\n  geom_col() +\n  geom_text(aes(label = paste0(round(Proportion*100,2),\"%\")), vjust = -.5, size = 3.5) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Number of Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Customer Type\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Age\ncustomer &lt;- customer |&gt;\n  mutate(`Customer Type` = ifelse(Churn == 1, \"Churn\", \"Non-Churn\"))\n\ncustomer |&gt;\n  ggplot(aes(x=Age, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Age between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Age\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Gender\ncustomer |&gt;\n  group_by(Gender, `Customer Type`) |&gt;\n  count() |&gt;\n  ggplot(aes(fill = Gender, y = n, x = `Customer Type`)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  geom_text(aes(label = n), vjust = -.5, size = 3,\n            position = position_dodge(width = 0.9)) +\n  scale_fill_brewer(palette = \"Set1\") +\n  ggtitle(\"Distribution of Male and Female Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Customer Type\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n#Tenure\ncustomer |&gt;\n  ggplot(aes(x= Tenure, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Tenure between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Tenure (Months)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Usage\ncustomer |&gt;\n  ggplot(aes(x= `Usage Frequency`, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Usage Frequency between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Usage Frequency (Days)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Suport Calls\ncustomer |&gt;\n  group_by(`Support Calls`, `Customer Type`) |&gt;\n  count() |&gt;\n  ggplot(aes(x = `Support Calls`, y = n, fill = `Customer Type`)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Number of Support Calls Made between Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Number of Support Calls Made\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Payment Delay\ncustomer |&gt;\n  ggplot(aes(x= `Payment Delay`, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Payment Delay between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Payment Delay (Days)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Subscription Type\ncustomer |&gt;\n  group_by(`Subscription Type`, `Customer Type`) |&gt;\n  count() |&gt;\n  ggplot(aes(fill = `Subscription Type`, y = n, x = `Customer Type`)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  geom_text(aes(label = n), vjust = -.5, size = 3,\n            position = position_dodge(width = 0.9)) +\n  scale_fill_brewer(palette = \"Pastel2\") +\n  ggtitle(\"Distribution of Subscription Type among Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Subscription Type\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Contract Length\ncustomer |&gt;\n  group_by(`Contract Length`, `Customer Type`) |&gt;\n  count() |&gt;\n  ggplot(aes(fill = `Contract Length`, y = n, x = `Customer Type`)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  geom_text(aes(label = n), vjust = -.5, size = 3,\n            position = position_dodge(width = 0.9)) +\n  scale_fill_brewer(palette = \"Paired\") +\n  ggtitle(\"Distribution of Contract Length among Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Contract Length\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Total Spend\ncustomer |&gt;\n  ggplot(aes(x= `Total Spend`, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Total Amount Spend between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Total Amount Spend ($)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Last Interaction\ncustomer |&gt;\n  ggplot(aes(x= `Last Interaction`, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Last Interaction between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Number of Day since their Last Interaction with the Company\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Matrix\ncolumns = c(\"Age\", \"Usage Frequency\", \"Support Calls\", \"Payment Delay\",\n            \"Total Spend\", \"Last Interaction\", \"Churn\")\ncustomer |&gt;\n  select(columns) |&gt;\n  correlate(use = \"pairwise.complete.obs\", method = \"pearson\") |&gt;\n  shave(upper = T) |&gt;\n  rplot(print_cor = TRUE)\n\n# Raster Plot\ncustomer |&gt;\n  dbplot_raster(x = `Support Calls`, y = `Churn`, fill = n(), resolution = 10) +\n  ggtitle(\"Relationship between Number of Support Calls and Churn\") +\n  ylab(\"Churn\") + xlab(\"Number of Support Calls Made\") +\n  scale_fill_continuous(name = \"Number of Customers\", trans = \"reverse\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())"
  },
  {
    "objectID": "docs/customer_churn_github.html#logistic-regression",
    "href": "docs/customer_churn_github.html#logistic-regression",
    "title": "Customer Churn Project",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\nFeature Engineering\nWe have applied various feature engineering techniques to pre-process our features and enhance their quality, before training our models to improve the overall performance.\nWe performed data binning on selected numeric variables, transforming them into categorical variables (Figure 14). Based on our EDA findings, we identify three variables - “Age”, “Total Spend” and “Payment Delay” - that display a non-monotonic relationship (step function) with the target variable. These variables exhibit a uniform distribution within specific intervals, leading us to bin them accordingly based on those intervals.\nWe built a Spark ML pipeline to integrate a series of transformation steps and algorithms on our train dataset into a single workflow. In the initial stage, we utilize the ft_standard_scaler function to standardise our numeric variables on a constant scale. This ensures that our numeric variables maintain a uniform scale and thus, prevents the model from being biassed towards variables with larger scales. Subsequently, we utilise ft_one_hot_encoder functions to encode categorical variables into numerical representations, generating binary columns for each distinct category (except for the base). This allows us to include those variables into our models since most algorithms require numeric inputs. In the final step of our process, following the transformation of our variables, we apply the ml_logistic_regression function on our dataset, given its suitability in binary classification and its ease in interpreting results.\ncustomer &lt;- customer |&gt;\n  mutate(`Age Group` = case_when(Age &gt;= 50 ~ \"Senior\",\n                                 Age &gt;= 40 ~ \"Middle\",\n                                 Age &gt;= 30 ~ \"Mid-Middle\",\n                                 TRUE ~ \"Young\"),\n         `Payment Group` = ifelse(`Payment Delay` &lt;= 20, \"Short\", \"Long\"),\n         `Spend Group` = ifelse(`Total Spend` &lt;= 500, \"Short\", \"Long\"))\n\n\nData Binning and Data set splitting\ncustomer &lt;- customer |&gt;\n  mutate(`Age Group` = case_when(Age &gt;= 50 ~ \"Senior\",\n                                 Age &gt;= 40 ~ \"Middle\",\n                                 Age &gt;= 30 ~ \"Mid-Middle\",\n                                 TRUE ~ \"Young\"),\n         `Payment Group` = ifelse(`Payment Delay` &lt;= 20, \"Short\", \"Long\"),\n         `Spend Group` = ifelse(`Total Spend` &lt;= 500, \"Short\", \"Long\"))\n\n# Separation of Dataset into Training and Testing sets\ncustomer_split &lt;- customer |&gt;\n  sdf_random_split(training = 0.7, testing = 0.3, seed = 1234)\n\ncustomer_train &lt;- customer_split$training\ncustomer_test &lt;- customer_split$testing\n\ncustomers_train &lt;- customer_train |&gt;\n  select(-CustomerID)\n\ncustomers_test &lt;- customer_test |&gt;\n  select(-CustomerID)\n\n\nModel 1 (Base Model with all variables and Cross-Validation)\nWe utilise the sdf_random_split function to partition our dataset into training and test subsets, with a 70-30 ratio, and set the seed to 1234 to ensure reproducibility. After constructing our ML pipeline, we employ the ml_fit function to fit the training dataset into the pipeline, generating a pipeline model. We then utilize the ml_transform function to execute the pipeline model on the test dataset which allows us to assess the performance of our model and evaluate its effectiveness in handling unseen data.\nWe decided to utilise three metrics - AreaUnderROC, Precision and Recall - to evaluate the performance of our model using the test dataset. They range from 0 to 1, with a higher value indicating better performance. The AreaUnderROC is useful in evaluating the model’s ability to classify between churn and non-churn customers at various thresholds.\nA confusion matrix was created to calculate the Precision and Recall of our model performance. Precision evaluates the accuracy of positive predictions made by our model, providing us with the proportion of actually churned customers among those predicted as churned. Recall measures our model’s ability to capture all actual churned customers, providing the proportion of correctly predicted churn customers among those who actually churned.\nHaving obtained our models, we can then look to employ regularisation techniques. Regularisation will help prevent overfitting of our model by imposing penalties on our coefficients. There are 3 regularisation techniques considered - LASSO Regularisation, Ridge Regularisation and Elastic Net Regularisation. In order to employ these 3 techniques, we have utilised the ml_cross_validator function to specify our alpha and lambda values. Whereby, elastic_net_param (alpha) has been set from 0 to 1 in increments of 0.2 and reg_param (lambda) has taken the values of 0.001, 0.005 and 0.01. Performance Metric ROC is then used to identify the best set of hyperparameters to be reimplemented into the initial pipeline.\n\nModel 1\n# Logistic Modelling - Model 1\n\npipeline_1 &lt;- ml_pipeline(sc) |&gt;\n  ft_vector_assembler(\n    input_cols = c(\"Tenure\", \"Usage Frequency\", \"Support Calls\",\n                   \"Last Interaction\"),\n    output_col = \"features\") |&gt;\n\n  ft_standard_scaler(\n    input_col = \"features\",\n    output_col = \"stdz_features\",\n    with_mean = TRUE) |&gt;\n\n  ft_string_indexer(\n    input_col = \"Gender\",\n    output_col = \"Gender_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Subscription Type\",\n    output_col = \"Subscription_Type_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Contract Length\",\n    output_col = \"Contract_Length_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Age Group\",\n    output_col = \"Age_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Payment Group\",\n    output_col = \"Payment_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Spend Group\",\n    output_col = \"Spend_Group_indexed\") |&gt;\n\n  ft_one_hot_encoder(\n    input_cols = c(\"Gender_indexed\", \"Subscription_Type_indexed\",\n                   \"Contract_Length_indexed\",\"Age_Group_indexed\",\n                   \"Payment_Group_indexed\", \"Spend_Group_indexed\"),\n    output_cols = c(\"Gender_encoded\", \"Subscription_Type_encoded\",\n                    \"Contract_Length_encoded\", \"Age_Group_encoded\",\n                    \"Payment_Group_encoded\", \"Spend_Group_encoded\")) |&gt;\n\n  ft_vector_assembler(\n    input_cols = c(\"stdz_features\", \"Gender_encoded\", \"Age_Group_encoded\",\n                   \"Subscription_Type_encoded\", \"Contract_Length_encoded\",\n                   \"Payment_Group_encoded\", \"Spend_Group_encoded\"),\n    output_col = \"final_features\") |&gt;\n\n  ml_logistic_regression(\n    features_col = \"final_features\",\n    label_col = \"Churn\")\n\npipeline_model_1 &lt;- ml_fit(pipeline_1, customer_train)\npred.test_1 &lt;- ml_transform(pipeline_model_1, dataset = customer_test)\n\n\nauc.test_1 &lt;- pred.test_1 |&gt;\n  ml_binary_classification_evaluator(\n    label_col = \"Churn\",\n    prediction_col  = \"prediction\",\n    metric_name = \"areaUnderROC\"\n  )\n\nprint(paste0(\"AUC for model 1: \", auc.test_1))\n\n### Performance Metrics\nTP_1 &lt;- pred.test_1 |&gt;\n  filter(Churn == 1 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFP_1 &lt;- pred.test_1 |&gt;\n  filter(Churn == 0 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nTN_1 &lt;- pred.test_1 |&gt;\n  filter(Churn == 0 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFN_1 &lt;- pred.test_1 |&gt;\n  filter(Churn == 1 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\n\nConfusion_Matrix_1 &lt;- matrix(data = c(TP_1,FP_1,FN_1,TN_1),nrow = 2)\nAccuracy_1 &lt;- (TP_1 + TN_1) / (TP_1 + FP_1 + TN_1 + FN_1)\nPrecision_1 &lt;- TP_1 / (TP_1 + FP_1)\nType1_error_1 &lt;- FP_1 / (FP_1 + TN_1)\nType2_error_1 &lt;- FN_1 / (FN_1 + TP_1)\nRecall_1 &lt;- TP_1/(TP_1 + FN_1)\n\nCM_stats_1 &lt;- data.frame(Accuracy_1,Precision_1,Type1_error_1,Type2_error_1, Recall_1) |&gt;\n  rename(accuracy = count, precision = count.1, \"Type 1 error\" = count.2,\n         \"Type 2 error\" = count.3, Recall_1 = count.4)\n\nprint(\"Confusion matrix for model 1:\")\nConfusion_Matrix_1\nCM_stats_1\n[1] \"AUC for model 1: 0.935469957012298\"\n[1] \"Confusion matrix for model 1:\"\n     [,1]  [,2]  \n[1,] 73745 10198 \n[2,] 8608  58403\n  accuracy precision Type 1 error Type 2 error  Recall_1 \n1 0.875419 0.8954744    0.1284565    0.1214872 0.8785128\n\n\nModel 1 with Cross Validation\nApplying regularisation, it was determined that the best set of values were 0 and 0.001 for alpha and lambda values respectively. This indicates that a LASSO regularisation was favoured over the other 2 regularisation techniques. Model 1 (CV)’s performance metrics can be viewed in the table below.\n# Logistic Modelling - Model 1 (CV)\n\ncv &lt;- ml_cross_validator(\n  sc,\n  estimator = pipeline_1,\n  estimator_param_maps = list(\n    logistic_regression = list(\n      elastic_net_param = c(0, 0.20, 0.40, 0.60, 0.80, 1),\n      reg_param = c(0.001,0.005,0.01)\n    )\n  ),\n  evaluator = ml_binary_classification_evaluator(\n    sc,\n    label_col = \"Churn\"\n  ),\n  num_folds = 10,\n    parallelism = 6,\n  seed = 1234\n)\n\ncv_model &lt;- ml_fit(cv, customer_train)\n\nml_validation_metrics(cv_model) |&gt;\n  arrange(desc(areaUnderROC))\n\npipeline_2 &lt;- ml_pipeline(sc) |&gt;\n  ft_vector_assembler(\n    input_cols = c(\"Tenure\", \"Usage Frequency\", \"Support Calls\",\n                   \"Last Interaction\"),\n    output_col = \"features\") |&gt;\n\n  ft_standard_scaler(\n    input_col = \"features\",\n    output_col = \"stdz_features\",\n    with_mean = TRUE) |&gt;\n\n  ft_string_indexer(\n    input_col = \"Gender\",\n    output_col = \"Gender_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Subscription Type\",\n    output_col = \"Subscription_Type_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Contract Length\",\n    output_col = \"Contract_Length_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Age Group\",\n    output_col = \"Age_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Payment Group\",\n    output_col = \"Payment_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Spend Group\",\n    output_col = \"Spend_Group_indexed\") |&gt;\n\n  ft_one_hot_encoder(\n    input_cols = c(\"Gender_indexed\", \"Subscription_Type_indexed\",\n                   \"Contract_Length_indexed\",\"Age_Group_indexed\",\n                   \"Payment_Group_indexed\", \"Spend_Group_indexed\"),\n    output_cols = c(\"Gender_encoded\", \"Subscription_Type_encoded\",\n                    \"Contract_Length_encoded\", \"Age_Group_encoded\",\n                    \"Payment_Group_encoded\", \"Spend_Group_encoded\")) |&gt;\n\n  ft_vector_assembler(\n    input_cols = c(\"stdz_features\", \"Gender_encoded\", \"Age_Group_encoded\",\n                   \"Subscription_Type_encoded\", \"Contract_Length_encoded\",\n                   \"Payment_Group_encoded\", \"Spend_Group_encoded\"),\n    output_col = \"final_features\") |&gt;\n\n  ml_logistic_regression(\n    elastic_net_param = 1,\n    reg_param = 0.001,\n    features_col = \"final_features\",\n    label_col = \"Churn\")\n\npipeline_model_2 &lt;- ml_fit(pipeline_2, customer_train)\npred.test_2 &lt;- ml_transform(pipeline_model_2, dataset = customer_test)\n\n### Performance Metrics\nauc.test_2 &lt;- pred.test_2 |&gt;\n  ml_binary_classification_evaluator(\n    label_col = \"Churn\",\n    prediction_col  = \"prediction\",\n    metric_name = \"areaUnderROC\"\n  )\n\nprint(paste0(\"AUC for model 1a: \", auc.test_2))\n\nTP_2 &lt;- pred.test_2 |&gt;\n  filter(Churn == 1 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFP_2 &lt;- pred.test_2 |&gt;\n  filter(Churn == 0 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nTN_2 &lt;- pred.test_2 |&gt;\n  filter(Churn == 0 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFN_2 &lt;- pred.test_2 |&gt;\n  filter(Churn == 1 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nConfusion_Matrix_2 &lt;- matrix(data = c(TP_2,FP_2,FN_2,TN_2),nrow = 2)\nAccuracy_2 &lt;- (TP_2 + TN_2) / (TP_2 + FP_2 + TN_2 + FN_2)\nPrecision_2 &lt;- TP_2 / (TP_2 + FP_2)\nType1_error_2 &lt;- FP_2 / (FP_2 + TN_2)\nType2_error_2 &lt;- FN_2 / (FN_2 + TP_2)\nRecall_2 &lt;- TP_2/(TP_2 + FN_2)\n\nCM_stats_2 &lt;- data.frame(Accuracy_2,Precision_2,Type1_error_2,Type2_error_2,Recall_2) |&gt;\n  rename(accuracy = count, precision = count.1, \"Type 1 error\" = count.2,\n         \"Type 2 error\" = count.3, Recall = count.4)\n\nprint(\"Confusion matrix for model 1a:\")\nConfusion_Matrix_2\nCM_stats_2\n   areaUnderROC elastic_net_param_1 reg_param_1 \n1     0.9353870                 0.8       0.001 \n2     0.9353867                 1.0       0.001 \n3     0.9353855                 0.6       0.001 \n4     0.9353814                 0.4       0.001 \n5     0.9353752                 0.2       0.001 \n6     0.9353685                 0.0       0.001 \n7     0.9352374                 0.0       0.005 \n8     0.9352316                 0.2       0.005 \n9     0.9352001                 0.4       0.005 \n10    0.9351576                 0.6       0.005 \n11    0.9350908                 0.8       0.005 \n12    0.9350408                 0.0       0.010 \n13    0.9349928                 1.0       0.005 \n14    0.9349554                 0.2       0.010 \n15    0.9348020                 0.4       0.010 \n16    0.9345296                 0.6       0.010 \n17    0.9341043                 0.8       0.010 \n18    0.9334750                 1.0       0.010\n[1] \"AUC for model 1a: 0.935482660776576\"\n[1] \"Confusion matrix for model 1a:\"\n     [,1]  [,2]  \n[1,] 73690 10253 \n[2,] 8536  58475\n   accuracy precision Type 1 error Type 2 error    Recall \n1 0.8755316 0.8961886    0.1273821    0.1221424 0.8778576\nIt is observed that there are slight improvements to the Model 1 (CV)’s performance relative to Model 1. In which, we observe that the ROC and Precision values increase in its 4th and 3rd significant figure respectively. Whereas, a decrease in Recall in its 3rd significant figure is observed.\n\n\n\nModel 2 (Base Model with selected variables and Cross-Validation)\nWe then look to create an alternative model that seeks to drop variables that seem to have less explanatory power in determining churned and non-churned customers. This is done primarily through EDA. It is subsequently determined that variables - Tenure, Subscription Type and Usage Frequency be dropped.\n\nModel 2\n# Logistic Modelling - Model 2 \n\npipeline_3 &lt;- ml_pipeline(sc) |&gt;\n  ft_vector_assembler(\n    input_cols = c(\"Support Calls\", \"Last Interaction\"),\n    output_col = \"features\") |&gt;\n\n  ft_standard_scaler(\n    input_col = \"features\",\n    output_col = \"stdz_features\",\n    with_mean = TRUE) |&gt;\n\n  ft_string_indexer(\n    input_col = \"Gender\",\n    output_col = \"Gender_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Contract Length\",\n    output_col = \"Contract_Length_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Age Group\",\n    output_col = \"Age_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Payment Group\",\n    output_col = \"Payment_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Spend Group\",\n    output_col = \"Spend_Group_indexed\") |&gt;\n\n  ft_one_hot_encoder(\n    input_cols = c(\"Gender_indexed\",\n                   \"Age_Group_indexed\", \"Contract_Length_indexed\",\n                   \"Payment_Group_indexed\", \"Spend_Group_indexed\"),\n    output_cols = c(\"Gender_encoded\",\n                    \"Age_Group_encoded\", \"Contract_Length_encoded\",\n                    \"Payment_Group_encoded\", \"Spend_Group_encoded\")) |&gt;\n\n  ft_vector_assembler(\n    input_cols = c(\"stdz_features\", \"Gender_encoded\", \"Age_Group_encoded\",\n                   \"Payment_Group_encoded\", \"Spend_Group_encoded\",\n                   \"Contract_Length_encoded\"),\n    output_col = \"final_features\") |&gt;\n\n  ml_logistic_regression(\n    features_col = \"final_features\",\n    label_col = \"Churn\")\n\npipeline_model_3 &lt;- ml_fit(pipeline_3, customer_train)\npred.test_3 &lt;- ml_transform(pipeline_model_3, dataset = customer_test)\n\nauc.test_3 &lt;- pred.test_3 |&gt;\n  ml_binary_classification_evaluator(\n    label_col = \"Churn\",\n    prediction_col  = \"prediction\",\n    metric_name = \"areaUnderROC\"\n  )\n\nprint(paste0(\"AUC for model 2: \", auc.test_3))\n\n### Performance Metrics\nTP_3 &lt;- pred.test_3 |&gt;\n  filter(Churn == 1 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFP_3 &lt;- pred.test_3 |&gt;\n  filter(Churn == 0 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nTN_3 &lt;- pred.test_3 |&gt;\n  filter(Churn == 0 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFN_3 &lt;- pred.test_3 |&gt;\n  filter(Churn == 1 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nConfusion_Matrix_3 &lt;- matrix(data = c(TP_3,FP_3,FN_3,TN_3),nrow = 2)\naccuracy_3 &lt;- (TP_3 + TN_3) / (TP_3 + FP_3 + TN_3 + FN_3)\nprecision_3 &lt;- TP_3 / (TP_3 + FP_3)\nType1_error_3 &lt;- FP_3 / (FP_3 + TN_3)\nType2_error_3 &lt;- FN_3 / (FN_3 + TP_3)\nRecall_3 &lt;- TP_3/(TP_3 + FN_3)\n\nCM_stats_3 &lt;- data.frame(accuracy_3,precision_3,Type1_error_3,Type2_error_3,Recall_3) |&gt;\n  rename(accuracy = count, precision = count.1, \"Type 1 error\" = count.2,\n         \"Type 2 error\" = count.3, Recall = count.4)\n\nprint(\"Confusion matrix for model 2:\")\nConfusion_Matrix_3\nCM_stats_3\n[1] \"AUC for model 2: 0.935282038899156\"\n[1] \"Confusion matrix for model 2:\"\n     [,1]  [,2]  \n[1,] 73731 10212 \n[2,] 8610  58401\n  accuracy precision Type 1 error Type 2 error   Recall \n1 0.875313 0.8954348    0.1284864     0.121654 0.878346\n\n\nModel 2 with Cross Validation\nAfter regularisation, it was determined that the best set of values were 0 and 0.001 for alpha and lambda values respectively. This indicates that a LASSO regularisation was favoured over the other 2 regularisation techniques. Model 2 (CV)’s performance metrics can be viewed in the table below.\n# Logistic Modelling - Model 2 (CV)\n\ncv_1 &lt;- ml_cross_validator(\n  sc,\n  estimator = pipeline_3,\n  estimator_param_maps = list(\n    logistic_regression = list(\n      elastic_net_param = c(0, 0.20, 0.40, 0.60, 0.80, 1),\n      reg_param = c(0.001,0.005,0.01)\n    )\n  ),\n  evaluator = ml_binary_classification_evaluator(\n    sc,\n    label_col = \"Churn\"\n  ),\n  num_folds = 10,\n    parallelism = 6,\n  seed = 1234\n)\n\ncv_model_1 &lt;- ml_fit(cv_1, customer_train)\n\nml_validation_metrics(cv_model_1) |&gt;\n  arrange(desc(areaUnderROC))\n\npipeline_4 &lt;- ml_pipeline(sc) |&gt;\n  ft_vector_assembler(\n    input_cols = c(\"Support Calls\", \"Last Interaction\"),\n    output_col = \"features\") |&gt;\n\n  ft_standard_scaler(\n    input_col = \"features\",\n    output_col = \"stdz_features\",\n    with_mean = TRUE) |&gt;\n\n  ft_string_indexer(\n    input_col = \"Gender\",\n    output_col = \"Gender_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Contract Length\",\n    output_col = \"Contract_Length_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Age Group\",\n    output_col = \"Age_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Payment Group\",\n    output_col = \"Payment_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Spend Group\",\n    output_col = \"Spend_Group_indexed\") |&gt;\n\n  ft_one_hot_encoder(\n    input_cols = c(\"Gender_indexed\",\n                   \"Age_Group_indexed\", \"Contract_Length_indexed\",\n                   \"Payment_Group_indexed\", \"Spend_Group_indexed\"),\n    output_cols = c(\"Gender_encoded\",\n                    \"Age_Group_encoded\", \"Contract_Length_encoded\",\n                    \"Payment_Group_encoded\", \"Spend_Group_encoded\")) |&gt;\n\n  ft_vector_assembler(\n    input_cols = c(\"stdz_features\", \"Gender_encoded\", \"Age_Group_encoded\",\n                   \"Payment_Group_encoded\", \"Spend_Group_encoded\",\n                   \"Contract_Length_encoded\"),\n    output_col = \"final_features\") |&gt;\n\n  ml_logistic_regression(\n    elastic_net_param = 1,\n    reg_param = 0.001,\n    features_col = \"final_features\",\n    label_col = \"Churn\")\n\npipeline_model_4 &lt;- ml_fit(pipeline_4, customer_train)\npred.test_4 &lt;- ml_transform(pipeline_model_4, dataset = customer_test)\n\n### Perfomance Metrics\nauc.test_4 &lt;- pred.test_4 |&gt;\n  ml_binary_classification_evaluator(\n    label_col = \"Churn\",\n    prediction_col  = \"prediction\",\n    metric_name = \"areaUnderROC\"\n  )\n\nprint(paste0(\"AUC for model 2a: \", auc.test_4))\n\nTP_4 &lt;- pred.test_4 |&gt;\n  filter(Churn == 1 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFP_4 &lt;- pred.test_4 |&gt;\n  filter(Churn == 0 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nTN_4 &lt;- pred.test_4 |&gt;\n  filter(Churn == 0 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFN_4 &lt;- pred.test_4 |&gt;\n  filter(Churn == 1 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nConfusion_Matrix_4 &lt;- matrix(data = c(TP_4,FP_4,FN_4,TN_4),nrow = 2)\naccuracy_4 &lt;- (TP_4 + TN_4) / (TP_4 + FP_4 + TN_4 + FN_4)\nprecision_4 &lt;- TP_4 / (TP_4 + FP_4)\nType1_error_4 &lt;- FP_4 / (FP_4 + TN_4)\nType2_error_4 &lt;- FN_4 / (FN_4 + TP_4)\nRecall_4 &lt;- TP_4/(TP_4 + FN_4)\n\nCM_stats_4 &lt;- data.frame(accuracy_4,precision_4,Type1_error_4,Type2_error_4,Recall_4) |&gt;\n  rename(accuracy = count, precision = count.1, \"Type 1 error\" = count.2,\n         \"Type 2 error\" = count.3, Recall = count.4)\n\nprint(\"Confusion matrix for model 2a:\")\nConfusion_Matrix_4\nCM_stats_4\n   areaUnderROC reg_param_1 elastic_net_param_1 \n  1     0.9351262       0.001                 1.0 \n  2     0.9351211       0.001                 0.8 \n  3     0.9351179       0.001                 0.6 \n  4     0.9351154       0.001                 0.4 \n  5     0.9351088       0.001                 0.2 \n  6     0.9351037       0.001                 0.0 \n  7     0.9349734       0.005                 0.0 \n  8     0.9349694       0.005                 0.2 \n  9     0.9349468       0.005                 0.4 \n  10    0.9349047       0.005                 0.6 \n  11    0.9348408       0.005                 0.8 \n  12    0.9347757       0.010                 0.0 \n  13    0.9347503       0.005                 1.0 \n  14    0.9347043       0.010                 0.2 \n  15    0.9345486       0.010                 0.4 \n  16    0.9342901       0.010                 0.6 \n  17    0.9338955       0.010                 0.8 \n  18    0.9333120       0.010                 1.0\n[1] \"AUC for model 2a: 0.935280551815638\"\n[1] \"Confusion matrix for model 2a:\"\n     [,1]  [,2] \n[1,] 73696 10247 \n[2,] 8568  58443\n   accuracy precision Type 1 error Type 2 error    Recall \n1 0.8753594 0.8958475    0.1278596    0.1220709 0.8779291\nComparing the differences in performance metrics between Model 3 and Model 3 (CV), there are little differences in their values. The same ROC values are obtained, Precision and Recall values increased and decreased in its 4th significant figure respectively."
  },
  {
    "objectID": "docs/customer_churn_github.html#conclusion",
    "href": "docs/customer_churn_github.html#conclusion",
    "title": "Customer Churn Project",
    "section": "Conclusion",
    "text": "Conclusion\nObserving across the performance metrics of the proposed models, there are little changes in values. In particular, changes including improvements to the values all occur within the 3rd or 4th significant figure which arguably does not represent major improvements across the models. Hence, this suggests that the models proposed have similar predictive capabilities. Keeping this in mind, we can pivot our focus to the principle of parsimony which favours simpler models over complex models without compromising on predictive power. Hence, the principle of parsimony dictates that Model 2 is more favourable due to having fewer variables. Furthermore, to prevent overfitting, regularisation techniques are applied, thus, we can conclude that Model 2 (CV) is an overall better model."
  },
  {
    "objectID": "docs/customer_churn_github.html#credits",
    "href": "docs/customer_churn_github.html#credits",
    "title": "Customer Churn Project",
    "section": "Credits",
    "text": "Credits\nChao Soon En Joy\nChen Xiangzhen Samson\nRachel Tan Yan Ning\nWee Su Ying"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "customer_churn_github.html",
    "href": "customer_churn_github.html",
    "title": "Customer Churn Project",
    "section": "",
    "text": "For this project, our group worked on a customer churn dataset. This dataset is centred around a telecommunications company, where it provides information on how customers are utilising the services and also indicates whether a customer has churned.\nThis project aims to propose a model to predict potential customer churners. To do so, spark will be leveraged to push computations and techniques such as exploratory data analysis and modelling will be employed."
  },
  {
    "objectID": "customer_churn_github.html#customer-churn-logistic-modelling",
    "href": "customer_churn_github.html#customer-churn-logistic-modelling",
    "title": "Customer Churn Project",
    "section": "",
    "text": "For this project, our group worked on a customer churn dataset. This dataset is centred around a telecommunications company, where it provides information on how customers are utilising the services and also indicates whether a customer has churned.\nThis project aims to propose a model to predict potential customer churners. To do so, spark will be leveraged to push computations and techniques such as exploratory data analysis and modelling will be employed."
  },
  {
    "objectID": "customer_churn_github.html#exploratory-data-analysis-eda",
    "href": "customer_churn_github.html#exploratory-data-analysis-eda",
    "title": "Customer Churn Project",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\nTo better understand our data set, we conducted EDA to examine the distribution of independent variables and their relationships with the dependent variable. To enhance the clarity in our visualizations, we labelled Churn (1 and 0) as “Churn” and “Non-Churn” respectively. The figures accompanying our analysis can be found in the Appendix.\n\nEDA Visualisations\n\nDistribution of Churn customers\n\nWe observe a relatively equal distribution of churn and non-churn customers, with 280,492 and 224,714 instances, respectively. This balanced class distribution ensures that the dataset will not introduce bias in model prediction and prevent the model from favouring the majority class.\n\n\nDistribution of Age between Churn customers\n\nWe can observe that among churn customers, age is uniformly distributed across the 20 to 60 years old range. In contrast, non-churn customers tend to be concentrated between 30 and 50 years old, with a notable decrease in the proportion of aged 50 to 60 years old. Since there is a notable difference in the distribution, Age is possibly a significant variable.\n\n\nDistribution of Gender between Churn customers\n\nWe notice that among churn customers, the number of males and females is quite similar. In contrast, among non-churn customers, there is a considerably higher count of males compared to females. Disparity in distribution suggests that Gender might be significant.\n\n\nDistribution of Tenure between Churn customers\n\nThe distribution of tenure does not show a notable disparity between churn and non-churn customers. There are minor variations, with non-churn customers showing slightly higher and lower proportions in the 10 and 20 months range respectively. This suggests that Tenure might be insignificant.\n\n\nDistribution of Usage Frequency between Churn customers\n\nThere is a small difference in the distribution of usage frequency within the 0-10 days range, with a slightly higher proportion of churn customers compared to non-churn customers. As such, Usage Frequency might be insignificant.\n\n\nDistribution of Support Calls between Churn customers\n\nThe majority of non-churn customers make fewer than 4 support calls. As a result, for support call counts less than 4, there are more non-churn customers than churn customers, while the opposite is observed for support call counts between 4 and 10. Notable difference in distribution suggests that Support Calls are significant.\n\n\nDistribution of Payment Delay between Churn customers\n\nWe observe that non-churn customers are concentrated in less than 20 days. However, among churn customers, the distribution is more even, with a slightly higher proportion having payment delays exceeding 20 days. Disparity in distribution seems to suggest that Payment Delay is significant.\n\n\nDistribution of Subscription Type between Churn customers\n\nWe do not observe any distinction in the subscription preferences among churn and non-churn customers respectively. Therefore, Subscription Type might be insignificant.\n\n\nDistribution of Contract Length between Churn customers\n\nWe noticed that non-churn customers tend to avoid signing up for monthly contracts. Whereas, for churn customers, there is a relatively even distribution. Huge difference in distribution suggests that Contact Length might be significant.\n\n\nDistribution of Spending Amount between Churn customers\n\nWe can observe that churn customers exhibit a relatively even distribution in terms of total amount spent, whereas non-churn customers tend to concentrate on total amount spent exceeding $500 range. Disparity in distribution seems to suggest that Total Spend might be significant.\n\n\nDistribution of Last Interaction between Churn customers\n\nWe observe that churn customers show a relatively even distribution in terms of the number of days since their last interaction with the company. In contrast, a significant proportion of non-churn customers are concentrated around less than 15 days since their last interaction. Notable difference in distribution suggests that Last Interaction is significant.\n\n\nCorrelation Matrix\n\n\n\n\nEDA Code\n# Churn vs Non-Churn\nsql &lt;- \"SELECT IF(Churn = 1.0, 'Churn', 'Non-Churn') AS `Customer Type`,\n        COUNT(Churn) AS `Number of Customers`,\n        COUNT(Churn) / SUM(COUNT(Churn)) OVER () AS Proportion\n        FROM Customer\n        GROUP BY Churn\"\n\nchurn &lt;- DBI::dbGetQuery(sc, sql)\n\nchurn &lt;- customer |&gt;\n  mutate(`Customer Type` = ifelse(Churn == 1.0, 'Churn', 'Non-Churn')) |&gt;\n  group_by(`Customer Type`) |&gt;\n  summarize(`Number of Customers` = n()) |&gt;\n  mutate(Proportion = `Number of Customers` / sum(`Number of Customers`)) |&gt;\n  collect()\n\nchurn |&gt;\n  ggplot(aes(x= `Customer Type`, y = `Number of Customers`, fill = `Customer Type`)) +\n  geom_col() +\n  geom_text(aes(label = paste0(round(Proportion*100,2),\"%\")), vjust = -.5, size = 3.5) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Number of Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Customer Type\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Age\ncustomer &lt;- customer |&gt;\n  mutate(`Customer Type` = ifelse(Churn == 1, \"Churn\", \"Non-Churn\"))\n\ncustomer |&gt;\n  ggplot(aes(x=Age, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Age between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Age\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Gender\ncustomer |&gt;\n  group_by(Gender, `Customer Type`) |&gt;\n  count() |&gt;\n  ggplot(aes(fill = Gender, y = n, x = `Customer Type`)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  geom_text(aes(label = n), vjust = -.5, size = 3,\n            position = position_dodge(width = 0.9)) +\n  scale_fill_brewer(palette = \"Set1\") +\n  ggtitle(\"Distribution of Male and Female Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Customer Type\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n#Tenure\ncustomer |&gt;\n  ggplot(aes(x= Tenure, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Tenure between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Tenure (Months)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Usage\ncustomer |&gt;\n  ggplot(aes(x= `Usage Frequency`, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Usage Frequency between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Usage Frequency (Days)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Suport Calls\ncustomer |&gt;\n  group_by(`Support Calls`, `Customer Type`) |&gt;\n  count() |&gt;\n  ggplot(aes(x = `Support Calls`, y = n, fill = `Customer Type`)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Number of Support Calls Made between Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Number of Support Calls Made\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Payment Delay\ncustomer |&gt;\n  ggplot(aes(x= `Payment Delay`, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Payment Delay between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Payment Delay (Days)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Subscription Type\ncustomer |&gt;\n  group_by(`Subscription Type`, `Customer Type`) |&gt;\n  count() |&gt;\n  ggplot(aes(fill = `Subscription Type`, y = n, x = `Customer Type`)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  geom_text(aes(label = n), vjust = -.5, size = 3,\n            position = position_dodge(width = 0.9)) +\n  scale_fill_brewer(palette = \"Pastel2\") +\n  ggtitle(\"Distribution of Subscription Type among Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Subscription Type\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Contract Length\ncustomer |&gt;\n  group_by(`Contract Length`, `Customer Type`) |&gt;\n  count() |&gt;\n  ggplot(aes(fill = `Contract Length`, y = n, x = `Customer Type`)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  geom_text(aes(label = n), vjust = -.5, size = 3,\n            position = position_dodge(width = 0.9)) +\n  scale_fill_brewer(palette = \"Paired\") +\n  ggtitle(\"Distribution of Contract Length among Churn and Non-Churn Customers\") +\n  ylab(\"Number of Customers\") + xlab(\"Contract Length\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Total Spend\ncustomer |&gt;\n  ggplot(aes(x= `Total Spend`, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Total Amount Spend between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Total Amount Spend ($)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Last Interaction\ncustomer |&gt;\n  ggplot(aes(x= `Last Interaction`, fill= `Customer Type`)) +\n  geom_density(alpha=.3) +\n  scale_fill_brewer(palette = \"Set2\") +\n  ggtitle(\"Distribution of Last Interaction between Churn and Non-Churn Customers\") +\n  ylab(\"Density\") + xlab(\"Number of Day since their Last Interaction with the Company\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())\n\n# Matrix\ncolumns = c(\"Age\", \"Usage Frequency\", \"Support Calls\", \"Payment Delay\",\n            \"Total Spend\", \"Last Interaction\", \"Churn\")\ncustomer |&gt;\n  select(columns) |&gt;\n  correlate(use = \"pairwise.complete.obs\", method = \"pearson\") |&gt;\n  shave(upper = T) |&gt;\n  rplot(print_cor = TRUE)\n\n# Raster Plot\ncustomer |&gt;\n  dbplot_raster(x = `Support Calls`, y = `Churn`, fill = n(), resolution = 10) +\n  ggtitle(\"Relationship between Number of Support Calls and Churn\") +\n  ylab(\"Churn\") + xlab(\"Number of Support Calls Made\") +\n  scale_fill_continuous(name = \"Number of Customers\", trans = \"reverse\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank())"
  },
  {
    "objectID": "customer_churn_github.html#logistic-regression",
    "href": "customer_churn_github.html#logistic-regression",
    "title": "Customer Churn Project",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\nFeature Engineering\nWe have applied various feature engineering techniques to pre-process our features and enhance their quality, before training our models to improve the overall performance.\nWe performed data binning on selected numeric variables, transforming them into categorical variables (Figure 14). Based on our EDA findings, we identify three variables - “Age”, “Total Spend” and “Payment Delay” - that display a non-monotonic relationship (step function) with the target variable. These variables exhibit a uniform distribution within specific intervals, leading us to bin them accordingly based on those intervals.\nWe built a Spark ML pipeline to integrate a series of transformation steps and algorithms on our train dataset into a single workflow. In the initial stage, we utilize the ft_standard_scaler function to standardise our numeric variables on a constant scale. This ensures that our numeric variables maintain a uniform scale and thus, prevents the model from being biassed towards variables with larger scales. Subsequently, we utilise ft_one_hot_encoder functions to encode categorical variables into numerical representations, generating binary columns for each distinct category (except for the base). This allows us to include those variables into our models since most algorithms require numeric inputs. In the final step of our process, following the transformation of our variables, we apply the ml_logistic_regression function on our dataset, given its suitability in binary classification and its ease in interpreting results.\ncustomer &lt;- customer |&gt;\n  mutate(`Age Group` = case_when(Age &gt;= 50 ~ \"Senior\",\n                                 Age &gt;= 40 ~ \"Middle\",\n                                 Age &gt;= 30 ~ \"Mid-Middle\",\n                                 TRUE ~ \"Young\"),\n         `Payment Group` = ifelse(`Payment Delay` &lt;= 20, \"Short\", \"Long\"),\n         `Spend Group` = ifelse(`Total Spend` &lt;= 500, \"Short\", \"Long\"))\n\n\nData Binning and Data set splitting\ncustomer &lt;- customer |&gt;\n  mutate(`Age Group` = case_when(Age &gt;= 50 ~ \"Senior\",\n                                 Age &gt;= 40 ~ \"Middle\",\n                                 Age &gt;= 30 ~ \"Mid-Middle\",\n                                 TRUE ~ \"Young\"),\n         `Payment Group` = ifelse(`Payment Delay` &lt;= 20, \"Short\", \"Long\"),\n         `Spend Group` = ifelse(`Total Spend` &lt;= 500, \"Short\", \"Long\"))\n\n# Separation of Dataset into Training and Testing sets\ncustomer_split &lt;- customer |&gt;\n  sdf_random_split(training = 0.7, testing = 0.3, seed = 1234)\n\ncustomer_train &lt;- customer_split$training\ncustomer_test &lt;- customer_split$testing\n\ncustomers_train &lt;- customer_train |&gt;\n  select(-CustomerID)\n\ncustomers_test &lt;- customer_test |&gt;\n  select(-CustomerID)\n\n\nModel 1 (Base Model with all variables and Cross-Validation)\nWe utilise the sdf_random_split function to partition our dataset into training and test subsets, with a 70-30 ratio, and set the seed to 1234 to ensure reproducibility. After constructing our ML pipeline, we employ the ml_fit function to fit the training dataset into the pipeline, generating a pipeline model. We then utilize the ml_transform function to execute the pipeline model on the test dataset which allows us to assess the performance of our model and evaluate its effectiveness in handling unseen data.\nWe decided to utilise three metrics - AreaUnderROC, Precision and Recall - to evaluate the performance of our model using the test dataset. They range from 0 to 1, with a higher value indicating better performance. The AreaUnderROC is useful in evaluating the model’s ability to classify between churn and non-churn customers at various thresholds.\nA confusion matrix was created to calculate the Precision and Recall of our model performance. Precision evaluates the accuracy of positive predictions made by our model, providing us with the proportion of actually churned customers among those predicted as churned. Recall measures our model’s ability to capture all actual churned customers, providing the proportion of correctly predicted churn customers among those who actually churned.\nHaving obtained our models, we can then look to employ regularisation techniques. Regularisation will help prevent overfitting of our model by imposing penalties on our coefficients. There are 3 regularisation techniques considered - LASSO Regularisation, Ridge Regularisation and Elastic Net Regularisation. In order to employ these 3 techniques, we have utilised the ml_cross_validator function to specify our alpha and lambda values. Whereby, elastic_net_param (alpha) has been set from 0 to 1 in increments of 0.2 and reg_param (lambda) has taken the values of 0.001, 0.005 and 0.01. Performance Metric ROC is then used to identify the best set of hyperparameters to be reimplemented into the initial pipeline.\n\nModel 1\n# Logistic Modelling - Model 1\n\npipeline_1 &lt;- ml_pipeline(sc) |&gt;\n  ft_vector_assembler(\n    input_cols = c(\"Tenure\", \"Usage Frequency\", \"Support Calls\",\n                   \"Last Interaction\"),\n    output_col = \"features\") |&gt;\n\n  ft_standard_scaler(\n    input_col = \"features\",\n    output_col = \"stdz_features\",\n    with_mean = TRUE) |&gt;\n\n  ft_string_indexer(\n    input_col = \"Gender\",\n    output_col = \"Gender_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Subscription Type\",\n    output_col = \"Subscription_Type_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Contract Length\",\n    output_col = \"Contract_Length_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Age Group\",\n    output_col = \"Age_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Payment Group\",\n    output_col = \"Payment_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Spend Group\",\n    output_col = \"Spend_Group_indexed\") |&gt;\n\n  ft_one_hot_encoder(\n    input_cols = c(\"Gender_indexed\", \"Subscription_Type_indexed\",\n                   \"Contract_Length_indexed\",\"Age_Group_indexed\",\n                   \"Payment_Group_indexed\", \"Spend_Group_indexed\"),\n    output_cols = c(\"Gender_encoded\", \"Subscription_Type_encoded\",\n                    \"Contract_Length_encoded\", \"Age_Group_encoded\",\n                    \"Payment_Group_encoded\", \"Spend_Group_encoded\")) |&gt;\n\n  ft_vector_assembler(\n    input_cols = c(\"stdz_features\", \"Gender_encoded\", \"Age_Group_encoded\",\n                   \"Subscription_Type_encoded\", \"Contract_Length_encoded\",\n                   \"Payment_Group_encoded\", \"Spend_Group_encoded\"),\n    output_col = \"final_features\") |&gt;\n\n  ml_logistic_regression(\n    features_col = \"final_features\",\n    label_col = \"Churn\")\n\npipeline_model_1 &lt;- ml_fit(pipeline_1, customer_train)\npred.test_1 &lt;- ml_transform(pipeline_model_1, dataset = customer_test)\n\n\nauc.test_1 &lt;- pred.test_1 |&gt;\n  ml_binary_classification_evaluator(\n    label_col = \"Churn\",\n    prediction_col  = \"prediction\",\n    metric_name = \"areaUnderROC\"\n  )\n\nprint(paste0(\"AUC for model 1: \", auc.test_1))\n\n### Performance Metrics\nTP_1 &lt;- pred.test_1 |&gt;\n  filter(Churn == 1 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFP_1 &lt;- pred.test_1 |&gt;\n  filter(Churn == 0 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nTN_1 &lt;- pred.test_1 |&gt;\n  filter(Churn == 0 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFN_1 &lt;- pred.test_1 |&gt;\n  filter(Churn == 1 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\n\nConfusion_Matrix_1 &lt;- matrix(data = c(TP_1,FP_1,FN_1,TN_1),nrow = 2)\nAccuracy_1 &lt;- (TP_1 + TN_1) / (TP_1 + FP_1 + TN_1 + FN_1)\nPrecision_1 &lt;- TP_1 / (TP_1 + FP_1)\nType1_error_1 &lt;- FP_1 / (FP_1 + TN_1)\nType2_error_1 &lt;- FN_1 / (FN_1 + TP_1)\nRecall_1 &lt;- TP_1/(TP_1 + FN_1)\n\nCM_stats_1 &lt;- data.frame(Accuracy_1,Precision_1,Type1_error_1,Type2_error_1, Recall_1) |&gt;\n  rename(accuracy = count, precision = count.1, \"Type 1 error\" = count.2,\n         \"Type 2 error\" = count.3, Recall_1 = count.4)\n\nprint(\"Confusion matrix for model 1:\")\nConfusion_Matrix_1\nCM_stats_1\n[1] \"AUC for model 1: 0.935469957012298\"\n[1] \"Confusion matrix for model 1:\"\n     [,1]  [,2]  \n[1,] 73745 10198 \n[2,] 8608  58403\n  accuracy precision Type 1 error Type 2 error  Recall_1 \n1 0.875419 0.8954744    0.1284565    0.1214872 0.8785128\n\n\nModel 1 with Cross Validation\nApplying regularisation, it was determined that the best set of values were 0 and 0.001 for alpha and lambda values respectively. This indicates that a LASSO regularisation was favoured over the other 2 regularisation techniques. Model 1 (CV)’s performance metrics can be viewed in the table below.\n# Logistic Modelling - Model 1 (CV)\n\ncv &lt;- ml_cross_validator(\n  sc,\n  estimator = pipeline_1,\n  estimator_param_maps = list(\n    logistic_regression = list(\n      elastic_net_param = c(0, 0.20, 0.40, 0.60, 0.80, 1),\n      reg_param = c(0.001,0.005,0.01)\n    )\n  ),\n  evaluator = ml_binary_classification_evaluator(\n    sc,\n    label_col = \"Churn\"\n  ),\n  num_folds = 10,\n    parallelism = 6,\n  seed = 1234\n)\n\ncv_model &lt;- ml_fit(cv, customer_train)\n\nml_validation_metrics(cv_model) |&gt;\n  arrange(desc(areaUnderROC))\n\npipeline_2 &lt;- ml_pipeline(sc) |&gt;\n  ft_vector_assembler(\n    input_cols = c(\"Tenure\", \"Usage Frequency\", \"Support Calls\",\n                   \"Last Interaction\"),\n    output_col = \"features\") |&gt;\n\n  ft_standard_scaler(\n    input_col = \"features\",\n    output_col = \"stdz_features\",\n    with_mean = TRUE) |&gt;\n\n  ft_string_indexer(\n    input_col = \"Gender\",\n    output_col = \"Gender_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Subscription Type\",\n    output_col = \"Subscription_Type_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Contract Length\",\n    output_col = \"Contract_Length_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Age Group\",\n    output_col = \"Age_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Payment Group\",\n    output_col = \"Payment_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Spend Group\",\n    output_col = \"Spend_Group_indexed\") |&gt;\n\n  ft_one_hot_encoder(\n    input_cols = c(\"Gender_indexed\", \"Subscription_Type_indexed\",\n                   \"Contract_Length_indexed\",\"Age_Group_indexed\",\n                   \"Payment_Group_indexed\", \"Spend_Group_indexed\"),\n    output_cols = c(\"Gender_encoded\", \"Subscription_Type_encoded\",\n                    \"Contract_Length_encoded\", \"Age_Group_encoded\",\n                    \"Payment_Group_encoded\", \"Spend_Group_encoded\")) |&gt;\n\n  ft_vector_assembler(\n    input_cols = c(\"stdz_features\", \"Gender_encoded\", \"Age_Group_encoded\",\n                   \"Subscription_Type_encoded\", \"Contract_Length_encoded\",\n                   \"Payment_Group_encoded\", \"Spend_Group_encoded\"),\n    output_col = \"final_features\") |&gt;\n\n  ml_logistic_regression(\n    elastic_net_param = 1,\n    reg_param = 0.001,\n    features_col = \"final_features\",\n    label_col = \"Churn\")\n\npipeline_model_2 &lt;- ml_fit(pipeline_2, customer_train)\npred.test_2 &lt;- ml_transform(pipeline_model_2, dataset = customer_test)\n\n### Performance Metrics\nauc.test_2 &lt;- pred.test_2 |&gt;\n  ml_binary_classification_evaluator(\n    label_col = \"Churn\",\n    prediction_col  = \"prediction\",\n    metric_name = \"areaUnderROC\"\n  )\n\nprint(paste0(\"AUC for model 1a: \", auc.test_2))\n\nTP_2 &lt;- pred.test_2 |&gt;\n  filter(Churn == 1 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFP_2 &lt;- pred.test_2 |&gt;\n  filter(Churn == 0 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nTN_2 &lt;- pred.test_2 |&gt;\n  filter(Churn == 0 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFN_2 &lt;- pred.test_2 |&gt;\n  filter(Churn == 1 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nConfusion_Matrix_2 &lt;- matrix(data = c(TP_2,FP_2,FN_2,TN_2),nrow = 2)\nAccuracy_2 &lt;- (TP_2 + TN_2) / (TP_2 + FP_2 + TN_2 + FN_2)\nPrecision_2 &lt;- TP_2 / (TP_2 + FP_2)\nType1_error_2 &lt;- FP_2 / (FP_2 + TN_2)\nType2_error_2 &lt;- FN_2 / (FN_2 + TP_2)\nRecall_2 &lt;- TP_2/(TP_2 + FN_2)\n\nCM_stats_2 &lt;- data.frame(Accuracy_2,Precision_2,Type1_error_2,Type2_error_2,Recall_2) |&gt;\n  rename(accuracy = count, precision = count.1, \"Type 1 error\" = count.2,\n         \"Type 2 error\" = count.3, Recall = count.4)\n\nprint(\"Confusion matrix for model 1a:\")\nConfusion_Matrix_2\nCM_stats_2\n   areaUnderROC elastic_net_param_1 reg_param_1 \n1     0.9353870                 0.8       0.001 \n2     0.9353867                 1.0       0.001 \n3     0.9353855                 0.6       0.001 \n4     0.9353814                 0.4       0.001 \n5     0.9353752                 0.2       0.001 \n6     0.9353685                 0.0       0.001 \n7     0.9352374                 0.0       0.005 \n8     0.9352316                 0.2       0.005 \n9     0.9352001                 0.4       0.005 \n10    0.9351576                 0.6       0.005 \n11    0.9350908                 0.8       0.005 \n12    0.9350408                 0.0       0.010 \n13    0.9349928                 1.0       0.005 \n14    0.9349554                 0.2       0.010 \n15    0.9348020                 0.4       0.010 \n16    0.9345296                 0.6       0.010 \n17    0.9341043                 0.8       0.010 \n18    0.9334750                 1.0       0.010\n[1] \"AUC for model 1a: 0.935482660776576\"\n[1] \"Confusion matrix for model 1a:\"\n     [,1]  [,2]  \n[1,] 73690 10253 \n[2,] 8536  58475\n   accuracy precision Type 1 error Type 2 error    Recall \n1 0.8755316 0.8961886    0.1273821    0.1221424 0.8778576\nIt is observed that there are slight improvements to the Model 1 (CV)’s performance relative to Model 1. In which, we observe that the ROC and Precision values increase in its 4th and 3rd significant figure respectively. Whereas, a decrease in Recall in its 3rd significant figure is observed.\n\n\n\nModel 2 (Base Model with selected variables and Cross-Validation)\nWe then look to create an alternative model that seeks to drop variables that seem to have less explanatory power in determining churned and non-churned customers. This is done primarily through EDA. It is subsequently determined that variables - Tenure, Subscription Type and Usage Frequency be dropped.\n\nModel 2\n# Logistic Modelling - Model 2 \n\npipeline_3 &lt;- ml_pipeline(sc) |&gt;\n  ft_vector_assembler(\n    input_cols = c(\"Support Calls\", \"Last Interaction\"),\n    output_col = \"features\") |&gt;\n\n  ft_standard_scaler(\n    input_col = \"features\",\n    output_col = \"stdz_features\",\n    with_mean = TRUE) |&gt;\n\n  ft_string_indexer(\n    input_col = \"Gender\",\n    output_col = \"Gender_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Contract Length\",\n    output_col = \"Contract_Length_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Age Group\",\n    output_col = \"Age_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Payment Group\",\n    output_col = \"Payment_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Spend Group\",\n    output_col = \"Spend_Group_indexed\") |&gt;\n\n  ft_one_hot_encoder(\n    input_cols = c(\"Gender_indexed\",\n                   \"Age_Group_indexed\", \"Contract_Length_indexed\",\n                   \"Payment_Group_indexed\", \"Spend_Group_indexed\"),\n    output_cols = c(\"Gender_encoded\",\n                    \"Age_Group_encoded\", \"Contract_Length_encoded\",\n                    \"Payment_Group_encoded\", \"Spend_Group_encoded\")) |&gt;\n\n  ft_vector_assembler(\n    input_cols = c(\"stdz_features\", \"Gender_encoded\", \"Age_Group_encoded\",\n                   \"Payment_Group_encoded\", \"Spend_Group_encoded\",\n                   \"Contract_Length_encoded\"),\n    output_col = \"final_features\") |&gt;\n\n  ml_logistic_regression(\n    features_col = \"final_features\",\n    label_col = \"Churn\")\n\npipeline_model_3 &lt;- ml_fit(pipeline_3, customer_train)\npred.test_3 &lt;- ml_transform(pipeline_model_3, dataset = customer_test)\n\nauc.test_3 &lt;- pred.test_3 |&gt;\n  ml_binary_classification_evaluator(\n    label_col = \"Churn\",\n    prediction_col  = \"prediction\",\n    metric_name = \"areaUnderROC\"\n  )\n\nprint(paste0(\"AUC for model 2: \", auc.test_3))\n\n### Performance Metrics\nTP_3 &lt;- pred.test_3 |&gt;\n  filter(Churn == 1 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFP_3 &lt;- pred.test_3 |&gt;\n  filter(Churn == 0 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nTN_3 &lt;- pred.test_3 |&gt;\n  filter(Churn == 0 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFN_3 &lt;- pred.test_3 |&gt;\n  filter(Churn == 1 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nConfusion_Matrix_3 &lt;- matrix(data = c(TP_3,FP_3,FN_3,TN_3),nrow = 2)\naccuracy_3 &lt;- (TP_3 + TN_3) / (TP_3 + FP_3 + TN_3 + FN_3)\nprecision_3 &lt;- TP_3 / (TP_3 + FP_3)\nType1_error_3 &lt;- FP_3 / (FP_3 + TN_3)\nType2_error_3 &lt;- FN_3 / (FN_3 + TP_3)\nRecall_3 &lt;- TP_3/(TP_3 + FN_3)\n\nCM_stats_3 &lt;- data.frame(accuracy_3,precision_3,Type1_error_3,Type2_error_3,Recall_3) |&gt;\n  rename(accuracy = count, precision = count.1, \"Type 1 error\" = count.2,\n         \"Type 2 error\" = count.3, Recall = count.4)\n\nprint(\"Confusion matrix for model 2:\")\nConfusion_Matrix_3\nCM_stats_3\n[1] \"AUC for model 2: 0.935282038899156\"\n[1] \"Confusion matrix for model 2:\"\n     [,1]  [,2]  \n[1,] 73731 10212 \n[2,] 8610  58401\n  accuracy precision Type 1 error Type 2 error   Recall \n1 0.875313 0.8954348    0.1284864     0.121654 0.878346\n\n\nModel 2 with Cross Validation\nAfter regularisation, it was determined that the best set of values were 0 and 0.001 for alpha and lambda values respectively. This indicates that a LASSO regularisation was favoured over the other 2 regularisation techniques. Model 2 (CV)’s performance metrics can be viewed in the table below.\n# Logistic Modelling - Model 2 (CV)\n\ncv_1 &lt;- ml_cross_validator(\n  sc,\n  estimator = pipeline_3,\n  estimator_param_maps = list(\n    logistic_regression = list(\n      elastic_net_param = c(0, 0.20, 0.40, 0.60, 0.80, 1),\n      reg_param = c(0.001,0.005,0.01)\n    )\n  ),\n  evaluator = ml_binary_classification_evaluator(\n    sc,\n    label_col = \"Churn\"\n  ),\n  num_folds = 10,\n    parallelism = 6,\n  seed = 1234\n)\n\ncv_model_1 &lt;- ml_fit(cv_1, customer_train)\n\nml_validation_metrics(cv_model_1) |&gt;\n  arrange(desc(areaUnderROC))\n\npipeline_4 &lt;- ml_pipeline(sc) |&gt;\n  ft_vector_assembler(\n    input_cols = c(\"Support Calls\", \"Last Interaction\"),\n    output_col = \"features\") |&gt;\n\n  ft_standard_scaler(\n    input_col = \"features\",\n    output_col = \"stdz_features\",\n    with_mean = TRUE) |&gt;\n\n  ft_string_indexer(\n    input_col = \"Gender\",\n    output_col = \"Gender_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Contract Length\",\n    output_col = \"Contract_Length_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Age Group\",\n    output_col = \"Age_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Payment Group\",\n    output_col = \"Payment_Group_indexed\") |&gt;\n\n  ft_string_indexer(\n    input_col = \"Spend Group\",\n    output_col = \"Spend_Group_indexed\") |&gt;\n\n  ft_one_hot_encoder(\n    input_cols = c(\"Gender_indexed\",\n                   \"Age_Group_indexed\", \"Contract_Length_indexed\",\n                   \"Payment_Group_indexed\", \"Spend_Group_indexed\"),\n    output_cols = c(\"Gender_encoded\",\n                    \"Age_Group_encoded\", \"Contract_Length_encoded\",\n                    \"Payment_Group_encoded\", \"Spend_Group_encoded\")) |&gt;\n\n  ft_vector_assembler(\n    input_cols = c(\"stdz_features\", \"Gender_encoded\", \"Age_Group_encoded\",\n                   \"Payment_Group_encoded\", \"Spend_Group_encoded\",\n                   \"Contract_Length_encoded\"),\n    output_col = \"final_features\") |&gt;\n\n  ml_logistic_regression(\n    elastic_net_param = 1,\n    reg_param = 0.001,\n    features_col = \"final_features\",\n    label_col = \"Churn\")\n\npipeline_model_4 &lt;- ml_fit(pipeline_4, customer_train)\npred.test_4 &lt;- ml_transform(pipeline_model_4, dataset = customer_test)\n\n### Perfomance Metrics\nauc.test_4 &lt;- pred.test_4 |&gt;\n  ml_binary_classification_evaluator(\n    label_col = \"Churn\",\n    prediction_col  = \"prediction\",\n    metric_name = \"areaUnderROC\"\n  )\n\nprint(paste0(\"AUC for model 2a: \", auc.test_4))\n\nTP_4 &lt;- pred.test_4 |&gt;\n  filter(Churn == 1 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFP_4 &lt;- pred.test_4 |&gt;\n  filter(Churn == 0 & prediction == 1) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nTN_4 &lt;- pred.test_4 |&gt;\n  filter(Churn == 0 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nFN_4 &lt;- pred.test_4 |&gt;\n  filter(Churn == 1 & prediction == 0) |&gt;\n  summarise(count = n()) |&gt;\n  collect()\n\nConfusion_Matrix_4 &lt;- matrix(data = c(TP_4,FP_4,FN_4,TN_4),nrow = 2)\naccuracy_4 &lt;- (TP_4 + TN_4) / (TP_4 + FP_4 + TN_4 + FN_4)\nprecision_4 &lt;- TP_4 / (TP_4 + FP_4)\nType1_error_4 &lt;- FP_4 / (FP_4 + TN_4)\nType2_error_4 &lt;- FN_4 / (FN_4 + TP_4)\nRecall_4 &lt;- TP_4/(TP_4 + FN_4)\n\nCM_stats_4 &lt;- data.frame(accuracy_4,precision_4,Type1_error_4,Type2_error_4,Recall_4) |&gt;\n  rename(accuracy = count, precision = count.1, \"Type 1 error\" = count.2,\n         \"Type 2 error\" = count.3, Recall = count.4)\n\nprint(\"Confusion matrix for model 2a:\")\nConfusion_Matrix_4\nCM_stats_4\n   areaUnderROC reg_param_1 elastic_net_param_1 \n  1     0.9351262       0.001                 1.0 \n  2     0.9351211       0.001                 0.8 \n  3     0.9351179       0.001                 0.6 \n  4     0.9351154       0.001                 0.4 \n  5     0.9351088       0.001                 0.2 \n  6     0.9351037       0.001                 0.0 \n  7     0.9349734       0.005                 0.0 \n  8     0.9349694       0.005                 0.2 \n  9     0.9349468       0.005                 0.4 \n  10    0.9349047       0.005                 0.6 \n  11    0.9348408       0.005                 0.8 \n  12    0.9347757       0.010                 0.0 \n  13    0.9347503       0.005                 1.0 \n  14    0.9347043       0.010                 0.2 \n  15    0.9345486       0.010                 0.4 \n  16    0.9342901       0.010                 0.6 \n  17    0.9338955       0.010                 0.8 \n  18    0.9333120       0.010                 1.0\n[1] \"AUC for model 2a: 0.935280551815638\"\n[1] \"Confusion matrix for model 2a:\"\n     [,1]  [,2] \n[1,] 73696 10247 \n[2,] 8568  58443\n   accuracy precision Type 1 error Type 2 error    Recall \n1 0.8753594 0.8958475    0.1278596    0.1220709 0.8779291\nComparing the differences in performance metrics between Model 3 and Model 3 (CV), there are little differences in their values. The same ROC values are obtained, Precision and Recall values increased and decreased in its 4th significant figure respectively."
  },
  {
    "objectID": "customer_churn_github.html#conclusion",
    "href": "customer_churn_github.html#conclusion",
    "title": "Customer Churn Project",
    "section": "Conclusion",
    "text": "Conclusion\nObserving across the performance metrics of the proposed models, there are little changes in values. In particular, changes including improvements to the values all occur within the 3rd or 4th significant figure which arguably does not represent major improvements across the models. Hence, this suggests that the models proposed have similar predictive capabilities. Keeping this in mind, we can pivot our focus to the principle of parsimony which favours simpler models over complex models without compromising on predictive power. Hence, the principle of parsimony dictates that Model 2 is more favourable due to having fewer variables. Furthermore, to prevent overfitting, regularisation techniques are applied, thus, we can conclude that Model 2 (CV) is an overall better model."
  },
  {
    "objectID": "customer_churn_github.html#credits",
    "href": "customer_churn_github.html#credits",
    "title": "Customer Churn Project",
    "section": "Credits",
    "text": "Credits\nChao Soon En Joy\nChen Xiangzhen Samson\nRachel Tan Yan Ning\nWee Su Ying"
  }
]